{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-17T10:13:27.441609Z",
     "iopub.status.busy": "2025-05-17T10:13:27.440819Z",
     "iopub.status.idle": "2025-05-17T10:13:27.448750Z",
     "shell.execute_reply": "2025-05-17T10:13:27.447981Z",
     "shell.execute_reply.started": "2025-05-17T10:13:27.441584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/masked-email/masked_emails (1).csv\n",
      "/kaggle/input/email-type/Email-type.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:58:55.258798Z",
     "iopub.status.busy": "2025-05-17T08:58:55.258411Z",
     "iopub.status.idle": "2025-05-17T08:59:45.098547Z",
     "shell.execute_reply": "2025-05-17T08:59:45.097786Z",
     "shell.execute_reply.started": "2025-05-17T08:58:55.258772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) Install & download spaCy models\n",
    "# Install required libraries\n",
    "!pip install datasets presidio-analyzer presidio-anonymizer accelerate==0.27.2\n",
    "!pip install transformers==4.39.3 peft==0.10.0\n",
    "!pip install -q evaluate\n",
    "\n",
    "\n",
    "!python -m spacy download en_core_web_lg --quiet\n",
    "!python -m spacy download de_core_news_md --quiet\n",
    "!python -m spacy download es_core_news_md --quiet\n",
    "!python -m spacy download fr_core_news_md --quiet\n",
    "!python -m spacy download pt_core_news_md --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T10:01:46.459825Z",
     "iopub.status.busy": "2025-05-17T10:01:46.459501Z",
     "iopub.status.idle": "2025-05-17T10:01:55.918609Z",
     "shell.execute_reply": "2025-05-17T10:01:55.918049Z",
     "shell.execute_reply.started": "2025-05-17T10:01:46.459803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from presidio_analyzer import (\n",
    "    RecognizerRegistry,\n",
    "    AnalyzerEngine,\n",
    "    PatternRecognizer,\n",
    "    Pattern,\n",
    ")\n",
    "from presidio_analyzer.predefined_recognizers import (\n",
    "    EmailRecognizer,\n",
    "    PhoneRecognizer,\n",
    "    DateRecognizer,\n",
    "    CreditCardRecognizer,\n",
    "    SpacyRecognizer,\n",
    ")\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "\n",
    "nlp_conf = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [\n",
    "        {\"lang_code\": code, \"model_name\": model}\n",
    "        for code, model in [\n",
    "            (\"en\", \"en_core_web_lg\"),\n",
    "            (\"de\", \"de_core_news_md\"),\n",
    "            (\"es\", \"es_core_news_md\"),\n",
    "            (\"fr\", \"fr_core_news_md\"),\n",
    "            (\"pt\", \"pt_core_news_md\"),\n",
    "            (\"nl\", \"nl_core_news_md\"),\n",
    "            (\"it\", \"it_core_news_md\"),\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "nlp_engine = NlpEngineProvider(nlp_configuration=nlp_conf).create_engine()\n",
    "\n",
    "registry = RecognizerRegistry()\n",
    "\n",
    "registry.supported_languages = [\"en\", \"de\", \"es\", \"fr\", \"pt\", \"nl\", \"it\"]\n",
    "\n",
    "enhancer = LemmaContextAwareEnhancer(\n",
    "    context_similarity_factor=0.35,\n",
    "    min_score_with_context_similarity=0.4,\n",
    "    context_prefix_count=3,\n",
    "    context_suffix_count=3,\n",
    ")\n",
    "\n",
    "language_contexts = {\n",
    "    \"en\": {\n",
    "        \"person\": [\"name\", \"called\", \"i am\", \"my name is\"],\n",
    "        \"email\": [\"email\", \"e-mail\", \"mail address\"],\n",
    "        \"phone\": [\"phone\", \"tel\", \"mobile number\"],\n",
    "        \"date\": [\"born\", \"dob\", \"birthdate\", \"birth date\"],\n",
    "        \"card\": [\"card\", \"credit\", \"debit\", \"cvv\", \"expiry\"],\n",
    "    },\n",
    "    \"de\": {\n",
    "        \"person\": [\"name\", \"heiße\", \"ich bin\", \"mein name ist\", \"herr\", \"frau\"],\n",
    "        \"email\": [\"e-mail\", \"mail\", \"email-adresse\"],\n",
    "        \"phone\": [\"telefon\", \"handy\", \"telefonnummer\"],\n",
    "        \"date\": [\"geburtsdatum\", \"geburtstag\", \"datum\"],\n",
    "        \"card\": [\"karte\", \"kreditkarte\", \"debitkarte\", \"ablaufdatum\", \"cvv\"],\n",
    "    },\n",
    "    \"es\": {\n",
    "        \"person\": [\"nombre\", \"me llamo\", \"soy\", \"mi nombre es\", \"señor\", \"señora\"],\n",
    "        \"email\": [\"correo\", \"electrónico\", \"correo electrónico\"],\n",
    "        \"phone\": [\"teléfono\", \"móvil\", \"número de teléfono\"],\n",
    "        \"date\": [\"nacimiento\", \"fecha de nacimiento\"],\n",
    "        \"card\": [\"tarjeta\", \"crédito\", \"débito\", \"cvv\", \"fecha de vencimiento\"],\n",
    "    },\n",
    "    \"fr\": {\n",
    "        \"person\": [\n",
    "            \"nom\",\n",
    "            \"je suis\",\n",
    "            \"je m’appelle\",\n",
    "            \"mon nom est\",\n",
    "            \"monsieur\",\n",
    "            \"madame\",\n",
    "        ],\n",
    "        \"email\": [\"courriel\", \"email\", \"adresse électronique\"],\n",
    "        \"phone\": [\"téléphone\", \"portable\", \"numéro de téléphone\"],\n",
    "        \"date\": [\"naissance\", \"date de naissance\"],\n",
    "        \"card\": [\"carte\", \"crédit\", \"débit\", \"cvv\", \"date d’expiration\"],\n",
    "    },\n",
    "    \"pt\": {\n",
    "        \"person\": [\"nome\", \"me chamo\", \"sou\", \"meu nome é\"],\n",
    "        \"email\": [\"email\", \"correio\", \"endereço de email\"],\n",
    "        \"phone\": [\"telefone\", \"celular\", \"número de telefone\"],\n",
    "        \"date\": [\"nascimento\", \"data de nascimento\"],\n",
    "        \"card\": [\"cartão\", \"crédito\", \"débito\", \"cvv\", \"validade\"],\n",
    "    },\n",
    "    \"it\": {\n",
    "        \"person\": [\"nome\", \"mi chiamo\", \"sono\", \"il mio nome è\", \"signor\", \"signora\"],\n",
    "        \"email\": [\"email\", \"indirizzo email\", \"posta elettronica\"],\n",
    "        \"phone\": [\"telefono\", \"numero di telefono\", \"cellulare\"],\n",
    "        \"date\": [\"nascita\", \"data di nascita\", \"compleanno\"],\n",
    "        \"card\": [\n",
    "            \"carta\",\n",
    "            \"carta di credito\",\n",
    "            \"carta di debito\",\n",
    "            \"numero carta\",\n",
    "            \"cvv\",\n",
    "            \"scadenza\",\n",
    "        ],\n",
    "    },\n",
    "    \"nl\": {\n",
    "        \"person\": [\n",
    "            \"naam\",\n",
    "            \"ik ben\",\n",
    "            \"mijn naam is\",\n",
    "            \"voornaam\",\n",
    "            \"achternaam\",\n",
    "            \"dhr\",\n",
    "            \"mevrouw\",\n",
    "        ],\n",
    "        \"email\": [\"e-mail\", \"e-mailadres\", \"emailadres\"],\n",
    "        \"phone\": [\"telefoon\", \"telefoonnummer\", \"mobiel nummer\", \"mobiele telefoon\"],\n",
    "        \"date\": [\"geboortedatum\", \"verjaardag\", \"datum van geboorte\"],\n",
    "        \"card\": [\n",
    "            \"kaart\",\n",
    "            \"creditcard\",\n",
    "            \"debetkaart\",\n",
    "            \"pinpas\",\n",
    "            \"bankkaart\",\n",
    "            \"kaartnummer\",\n",
    "            \"cvv\",\n",
    "            \"vervaldatum\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "for lang, ctx in language_contexts.items():\n",
    "    \n",
    "    registry.add_recognizer(\n",
    "        SpacyRecognizer(\n",
    "            supported_language=lang,\n",
    "            supported_entities=[\"PERSON\"],\n",
    "            context=ctx[\"person\"],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    registry.add_recognizer(\n",
    "        EmailRecognizer(supported_language=lang, context=ctx[\"email\"])\n",
    "    )\n",
    "    registry.add_recognizer(\n",
    "        PhoneRecognizer(supported_language=lang, context=ctx[\"phone\"])\n",
    "    )\n",
    "    registry.add_recognizer(\n",
    "        DateRecognizer(supported_language=lang, context=ctx[\"date\"])\n",
    "    )\n",
    "    registry.add_recognizer(\n",
    "        CreditCardRecognizer(supported_language=lang, context=ctx[\"card\"])\n",
    "    )\n",
    "\n",
    "\n",
    "registry.add_recognizer(\n",
    "    PatternRecognizer(\n",
    "        supported_entity=\"IN_AADHAAR\",\n",
    "        patterns=[Pattern(\"aadhar\", r\"\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b\", 0.8)],\n",
    "        context=[\"aadhar\", \"uidai\"],\n",
    "    )\n",
    ")\n",
    "registry.add_recognizer(\n",
    "    PatternRecognizer(\n",
    "        supported_entity=\"CVV_NO\",\n",
    "        patterns=[Pattern(\"cvv\", r\"\\b\\d{3,4}\\b\", 0.7)],\n",
    "        context=[\"cvv\", \"cvc\", \"security code\"],\n",
    "    )\n",
    ")\n",
    "registry.add_recognizer(\n",
    "    PatternRecognizer(\n",
    "        supported_entity=\"EXPIRY_NO\",\n",
    "        patterns=[Pattern(\"expiry\", r\"\\b(0[1-9]|1[0-2])/(?:\\d{2}|\\d{4})\\b\", 0.7)],\n",
    "        context=[\"expiry\", \"valid thru\", \"valide\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "analyzer = AnalyzerEngine(\n",
    "    registry=registry,\n",
    "    nlp_engine=nlp_engine,\n",
    "    supported_languages=[\"en\", \"de\", \"es\", \"fr\", \"pt\", \"nl\", \"it\"],\n",
    "    context_aware_enhancer=enhancer,\n",
    "    default_score_threshold=0.3,\n",
    ")\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "\n",
    "pres_map = {\n",
    "    \"PERSON\": \"[full_name]\",\n",
    "    \"EMAIL_ADDRESS\": \"[email]\",\n",
    "    \"PHONE_NUMBER\": \"[phone_number]\",\n",
    "    \"DATE_TIME\": \"[dob]\",\n",
    "    \"IN_AADHAAR\": \"[aadhar_num]\",\n",
    "    \"CREDIT_CARD\": \"[credit_debit_no]\",\n",
    "    \"CVV_NO\": \"[cvv_no]\",\n",
    "    \"EXPIRY_NO\": \"[expiry_no]\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def merge_spans(spans):\n",
    "    spans = sorted(spans, key=lambda x: x.start)\n",
    "    merged = []\n",
    "    for s in spans:\n",
    "        if merged and s.start <= merged[-1].end:\n",
    "            \n",
    "            if (s.end - s.start) > (merged[-1].end - merged[-1].start):\n",
    "                merged[-1] = s\n",
    "        else:\n",
    "            merged.append(s)\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def mask_pii(text: str):\n",
    "\n",
    "    detections = []\n",
    "    for lang in [\"en\", \"de\", \"es\", \"fr\", \"pt\", \"nl\", \"it\"]:\n",
    "        detections += analyzer.analyze(\n",
    "            text=text,\n",
    "            language=lang,\n",
    "            entities=list(pres_map.keys()),\n",
    "            score_threshold=0.3,\n",
    "        )\n",
    "\n",
    "\n",
    "    spans = merge_spans(detections)\n",
    "\n",
    "\n",
    "    operators = {\n",
    "        ent: OperatorConfig(\"replace\", {\"new_value\": tok})\n",
    "        for ent, tok in pres_map.items()\n",
    "    }\n",
    "\n",
    " \n",
    "    result = anonymizer.anonymize(\n",
    "        text=text,\n",
    "        analyzer_results=spans,\n",
    "        operators={\n",
    "            ent: OperatorConfig(\"replace\", {\"new_value\": tok})\n",
    "            for ent, tok in pres_map.items()\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "    masked_text = result.text\n",
    "    entities = []\n",
    "    for s in spans:\n",
    "        token = pres_map[s.entity_type]\n",
    "        entities.append(\n",
    "            {\n",
    "                \"position\": [s.start, s.end],\n",
    "                \"classification\": token.strip(\"[]\"),\n",
    "                \"entity\": text[s.start : s.end],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return masked_text, entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T09:00:11.386369Z",
     "iopub.status.busy": "2025-05-17T09:00:11.386144Z",
     "iopub.status.idle": "2025-05-17T09:00:19.150695Z",
     "shell.execute_reply": "2025-05-17T09:00:19.150151Z",
     "shell.execute_reply.started": "2025-05-17T09:00:11.386350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# 1. Load original data for training\n",
    "ds = load_dataset(\"csv\",data_files=\"/kaggle/input/email-type/Email-type.csv\")[\"train\"]  \n",
    "\n",
    "# 2. Label encoding\n",
    "labels = ds.unique(\"type\")\n",
    "label2id = {l:i for i,l in enumerate(labels)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "\n",
    "# 3. Tokenizer + model\n",
    "model_name=\"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(labels), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# 4. Preprocess\n",
    "def preprocess(batch):\n",
    "    enc = tokenizer(batch[\"email\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    enc[\"labels\"] = [label2id[l] for l in batch[\"type\"]]\n",
    "    return enc\n",
    "\n",
    "tok_ds = ds.map(preprocess, batched=True)\n",
    "\n",
    "# 5. Train/test split\n",
    "split = tok_ds.train_test_split(0.2, seed=42)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T09:00:19.152019Z",
     "iopub.status.busy": "2025-05-17T09:00:19.151481Z",
     "iopub.status.idle": "2025-05-17T09:00:19.161506Z",
     "shell.execute_reply": "2025-05-17T09:00:19.160843Z",
     "shell.execute_reply.started": "2025-05-17T09:00:19.151999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "\n",
    "hf_logging.set_verbosity_info()\n",
    "hf_logging.enable_progress_bar()\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy=\"steps\",    \n",
    "    eval_steps=200,                 \n",
    "    logging_strategy=\"steps\",       \n",
    "    logging_steps=100,              \n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",               \n",
    "    disable_tqdm=False              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T09:00:19.163412Z",
     "iopub.status.busy": "2025-05-17T09:00:19.163219Z",
     "iopub.status.idle": "2025-05-17T09:49:26.120964Z",
     "shell.execute_reply": "2025-05-17T09:49:26.120234Z",
     "shell.execute_reply.started": "2025-05-17T09:00:19.163396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 19,200\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Training with DataParallel so batch size has been adjusted to: 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1,800\n",
      "  Number of trainable parameters = 278,046,724\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 49:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.537806</td>\n",
       "      <td>0.748125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>0.514020</td>\n",
       "      <td>0.755625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.509888</td>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.481865</td>\n",
       "      <td>0.768750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.474850</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.489799</td>\n",
       "      <td>0.772917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.466206</td>\n",
       "      <td>0.776042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.466128</td>\n",
       "      <td>0.776250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.462707</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-600\n",
      "Configuration saved in ./results/checkpoint-600/config.json\n",
      "Model weights saved in ./results/checkpoint-600/model.safetensors\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1200\n",
      "Configuration saved in ./results/checkpoint-1200/config.json\n",
      "Model weights saved in ./results/checkpoint-1200/model.safetensors\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: type, email. If type, email are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1800\n",
      "Configuration saved in ./results/checkpoint-1800/config.json\n",
      "Model weights saved in ./results/checkpoint-1800/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to email_classifier\n",
      "Configuration saved in email_classifier/config.json\n",
      "Model weights saved in email_classifier/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split[\"train\"],\n",
    "    eval_dataset=split[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()  \n",
    "trainer.save_model(\"email_classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T10:31:08.753143Z",
     "iopub.status.busy": "2025-05-17T10:31:08.752799Z",
     "iopub.status.idle": "2025-05-17T10:31:12.561710Z",
     "shell.execute_reply": "2025-05-17T10:31:12.561075Z",
     "shell.execute_reply.started": "2025-05-17T10:31:08.753121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in email_classifier/config.json\n",
      "Model weights saved in email_classifier/model.safetensors\n",
      "tokenizer config file saved in email_classifier/tokenizer_config.json\n",
      "Special tokens file saved in email_classifier/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('email_classifier/tokenizer_config.json',\n",
       " 'email_classifier/special_tokens_map.json',\n",
       " 'email_classifier/sentencepiece.bpe.model',\n",
       " 'email_classifier/added_tokens.json',\n",
       " 'email_classifier/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"email_classifier\")\n",
    "tokenizer.save_pretrained(\"email_classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T10:07:51.421689Z",
     "iopub.status.busy": "2025-05-17T10:07:51.421106Z",
     "iopub.status.idle": "2025-05-17T10:07:52.224354Z",
     "shell.execute_reply": "2025-05-17T10:07:52.223771Z",
     "shell.execute_reply.started": "2025-05-17T10:07:51.421668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file email_classifier/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"email_classifier\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Incident\",\n",
      "    \"1\": \"Request\",\n",
      "    \"2\": \"Problem\",\n",
      "    \"3\": \"Change\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Change\": 3,\n",
      "    \"Incident\": 0,\n",
      "    \"Problem\": 2,\n",
      "    \"Request\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading configuration file email_classifier/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"email_classifier\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Incident\",\n",
      "    \"1\": \"Request\",\n",
      "    \"2\": \"Problem\",\n",
      "    \"3\": \"Change\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Change\": 3,\n",
      "    \"Incident\": 0,\n",
      "    \"Problem\": 2,\n",
      "    \"Request\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file email_classifier/model.safetensors\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at email_classifier.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load your fine-tuned classifier\n",
    "clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"email_classifier\",\n",
    "    tokenizer=tokenizer,\n",
    "    device=0  \n",
    ")\n",
    "\n",
    "def classify_email(input_email_body: str):\n",
    "    # a) Mask PII and collect entities\n",
    "    masked, entities = mask_pii(input_email_body)\n",
    "\n",
    "    # b) Classify the masked text\n",
    "    pred = clf(masked)[0]\n",
    "\n",
    "    # c) Return required JSON structure\n",
    "    return {\n",
    "        \"input_email_body\": input_email_body,\n",
    "        \"list_of_masked_entities\": entities,\n",
    "        \"masked_email\": masked,\n",
    "        \"category_of_the_email\": pred[\"label\"]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T10:10:18.922948Z",
     "iopub.status.busy": "2025-05-17T10:10:18.922632Z",
     "iopub.status.idle": "2025-05-17T10:10:19.013373Z",
     "shell.execute_reply": "2025-05-17T10:10:19.012669Z",
     "shell.execute_reply.started": "2025-05-17T10:10:18.922925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_email_body</th>\n",
       "      <th>list_of_masked_entities</th>\n",
       "      <th>masked_email</th>\n",
       "      <th>category_of_the_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Customer Support Inquiry Seeking information on digital strategies that can aid in brand growth and details on the available services. Looking forward to learning more to help our business grow My name is Elena Ivanova.. Thank you, and I look forward to hearing from you soon. You can reach me at fatima.farsi@help.com</td>\n",
       "      <td>[{'position': [214, 227], 'classification': 'PERSON', 'entity': 'Elena Ivanova'}, {'position': [230, 239], 'classification': 'PERSON', 'entity': 'Thank you'}, {'position': [306, 327], 'classification': 'EMAIL_ADDRESS', 'entity': 'fatima.farsi@help.com'}]</td>\n",
       "      <td>Subject: Customer Support Inquiry Seeking information on digital strategies that can aid in brand growth and details on the available services. Looking forward to learning more to help our business grow My name is [full_name].. [full_name], and I look forward to hearing from you soon. You can reach me at [email]</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                          input_email_body  \\\n",
       "0  Subject: Customer Support Inquiry Seeking information on digital strategies that can aid in brand growth and details on the available services. Looking forward to learning more to help our business grow My name is Elena Ivanova.. Thank you, and I look forward to hearing from you soon. You can reach me at fatima.farsi@help.com   \n",
       "\n",
       "                                                                                                                                                                                                                                          list_of_masked_entities  \\\n",
       "0  [{'position': [214, 227], 'classification': 'PERSON', 'entity': 'Elena Ivanova'}, {'position': [230, 239], 'classification': 'PERSON', 'entity': 'Thank you'}, {'position': [306, 327], 'classification': 'EMAIL_ADDRESS', 'entity': 'fatima.farsi@help.com'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                masked_email  \\\n",
       "0  Subject: Customer Support Inquiry Seeking information on digital strategies that can aid in brand growth and details on the available services. Looking forward to learning more to help our business grow My name is [full_name].. [full_name], and I look forward to hearing from you soon. You can reach me at [email]   \n",
       "\n",
       "  category_of_the_email  \n",
       "0               Request  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "result = classify_email(\n",
    "    \"Subject: Customer Support Inquiry Seeking information on digital strategies that can aid in brand growth and details on the available services. Looking forward to learning more to help our business grow My name is Elena Ivanova.. Thank you, and I look forward to hearing from you soon. You can reach me at fatima.farsi@help.com\"\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame([result])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T11:40:30.060116Z",
     "iopub.status.busy": "2025-05-17T11:40:30.059372Z",
     "iopub.status.idle": "2025-05-17T11:43:14.778976Z",
     "shell.execute_reply": "2025-05-17T11:43:14.778290Z",
     "shell.execute_reply.started": "2025-05-17T11:40:30.060092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/email_classifier.zip'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the model directory\n",
    "shutil.make_archive(\"email_classifier\", 'zip', \"email_classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T11:54:38.027100Z",
     "iopub.status.busy": "2025-05-17T11:54:38.026756Z",
     "iopub.status.idle": "2025-05-17T11:54:38.032359Z",
     "shell.execute_reply": "2025-05-17T11:54:38.031769Z",
     "shell.execute_reply.started": "2025-05-17T11:54:38.027078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='email_classifier.zip' target='_blank'>email_classifier.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/email_classifier.zip"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(r'email_classifier.zip')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7436658,
     "sourceId": 11836857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7443036,
     "sourceId": 11846093,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
